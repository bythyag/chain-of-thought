{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3c323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bfd306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load few-shot data\n",
    "file_location = \"/Users/thyag/Desktop/codes/chain-of-thought/dataset/arithmetic reasoning/gsm8k/base/gsm8k-base-gemini-2-0-flash.json\"\n",
    "with open(file_location, \"r\") as f:\n",
    "    few_shot_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db4049d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 72.0\n",
      "\n",
      "Prediction: 10.0\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: 16.0\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: 5.0\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: .\n",
      "\n",
      "Prediction: 43.0\n",
      "\n",
      "Prediction: 16.0\n",
      "\n",
      "Prediction: .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def normalize_numeric(value_str):\n",
    "    try:\n",
    "        return str(float(value_str))\n",
    "    except ValueError:\n",
    "        return value_str\n",
    "\n",
    "def openai_extract_final_answer(text):\n",
    "    \"\"\"\n",
    "    Use the OpenAI API to extract the main answer from the given text.\n",
    "    \"\"\"\n",
    "    # Note: The 'responses.create' endpoint is hypothetical.\n",
    "    # The standard is 'chat.completions.create'.\n",
    "    # This function is kept as-is from your example.\n",
    "    # If using a standard model like gpt-4o-mini, the call would look like this:\n",
    "    #\n",
    "    # response = client.chat.completions.create(\n",
    "    #      model=\"gpt-4o-mini\",\n",
    "    #      messages=[\n",
    "    #          {\"role\": \"system\", \"content\": \"Extract the final answer from the text. Only provide the final answer and nothing else. Do not include any reasoning or explanation.\"},\n",
    "    #          {\"role\": \"user\", \"content\": text}\n",
    "    #      ]\n",
    "    # )\n",
    "    # return response.choices[0].message.content\n",
    "    \n",
    "    # Using the hypothetical endpoint from your code\n",
    "    response = client.responses.create(\n",
    "         model=\"gpt-4o-mini-2024-08-06\",\n",
    "         instructions=\"Extract the final answer from the text. Only provide the final answer and nothing else. Do not include any reasoning or explanation.\",\n",
    "         input=text,\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "def extract_final_answer(text):\n",
    "    \"\"\"\n",
    "    Extract the final answer from text in various formats.\n",
    "    Works with numerical answers, multiple choice, true/false, and text answers.\n",
    "    For ambiguous cases, including empty input, falls back to using the OpenAI API.\n",
    "    \"\"\"\n",
    "    if text and text.strip():\n",
    "        cleaned_text = text.strip()\n",
    "        cleaned_text = re.sub(r'[\\*\\_`]', '', cleaned_text)\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "        # Numeric patterns: ensure we only match when context indicates explicit \"answer\"\n",
    "        patterns = [\n",
    "            r'answer\\s*(?:is|[:=])\\s*\\$?\\\\?boxed\\{?\\$?([\\d\\.]+)\\$?\\}?',\n",
    "            r'answer\\s*(?:is|[:=])\\s*([\\d\\.]+)',\n",
    "            r'final\\s*(?:answer|result)\\s*(?:[:=])\\s*([\\d\\.]+)',\n",
    "            r'result\\s*(?:is)?\\s*([\\d\\.]+)',\n",
    "            r'equals\\s+([\\d\\.]+)',\n",
    "            r'we get\\s+([\\d\\.]+)',\n",
    "            r'thus[,:\\s]+([\\d\\.]+)',\n",
    "            r'hence[,:\\s]+([\\d\\.]+)',\n",
    "            r'([\\d\\.]+)\\s+is\\s+the\\s+final\\s+answer',\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, cleaned_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return normalize_numeric(match.group(1))\n",
    "\n",
    "        mc_match = re.search(r'answer\\s*(?:is)?\\s*([A-D])[\\.:\\)]', cleaned_text, re.IGNORECASE)\n",
    "        if mc_match:\n",
    "            return mc_match.group(1).upper()\n",
    "\n",
    "        yn_match = re.search(r'answer\\s*(?:is)?\\s*(yes|no|true|false)', cleaned_text, re.IGNORECASE)\n",
    "        if yn_match:\n",
    "            return yn_match.group(1).lower()\n",
    "\n",
    "        text_match = re.search(r'answer\\s*(?:is|[:=])\\s*\"([^\"]+)\"', cleaned_text, re.IGNORECASE)\n",
    "        if text_match:\n",
    "            return text_match.group(1).strip()\n",
    "\n",
    "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "        if lines:\n",
    "            last_line = lines[-1]\n",
    "            for prefix in ['Answer:', 'Therefore,', 'Thus,']:\n",
    "                if last_line.startswith(prefix):\n",
    "                    answer_part = last_line[len(prefix):].strip()\n",
    "                    num_match = re.search(r'([\\d\\.]+)', answer_part)\n",
    "                    if num_match:\n",
    "                        return normalize_numeric(num_match.group(1))\n",
    "                    return answer_part\n",
    "            match = re.search(r'([\\d\\.]+)\\s*$', last_line)\n",
    "            if match:\n",
    "                return normalize_numeric(match.group(1))\n",
    "\n",
    "    try:\n",
    "        input_for_api = text or \"\" or \".\"\n",
    "        api_result = openai_extract_final_answer(input_for_api)\n",
    "        return api_result\n",
    "    except Exception:\n",
    "        return \"API_ERROR\"\n",
    "\n",
    "# Run the fixed function on the example data\n",
    "for i, example in enumerate(few_shot_data):\n",
    "    pred = extract_final_answer(example[\"answer_text\"])\n",
    "    print(f\"Prediction: {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e90b1637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: 72\n",
      "Example 2: 10\n",
      "Example 3: \n",
      "Example 4: \n",
      "Example 5: \n",
      "Example 6: \n",
      "Example 7: \n",
      "Example 8: 16\n",
      "Example 9: \n",
      "Example 10: \n",
      "Example 11: \n",
      "Example 12: \n",
      "Example 13: \n",
      "Example 14: \n",
      "Example 15: 5\n",
      "Example 16: \n",
      "Example 17: \n",
      "Example 18: 43\n",
      "Example 19: 16\n",
      "Example 20: \n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(few_shot_data):\n",
    "    pred = extract_final_answer(example[\"answer_text\"])\n",
    "    print(f\"Example {i+1}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: 72\n",
      "Example 2: 10\n",
      "Example 3: \n",
      "Example 4: \n",
      "Example 5: \n",
      "Example 6: \n",
      "Example 7: \n",
      "Example 8: 16\n",
      "Example 9: \n",
      "Example 10: \n",
      "Example 11: \n",
      "Example 12: \n",
      "Example 13: \n",
      "Example 14: \n",
      "Example 15: 5\n",
      "Example 16: \n",
      "Example 17: \n",
      "Example 18: 43\n",
      "Example 19: 16\n",
      "Example 20: \n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(few_shot_data):\n",
    "    pred = extract_final_answer(example[\"answer_text\"])\n",
    "    print(f\"Example {i+1}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ab7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: 72\n",
      "Example 2: 10\n",
      "Example 3: 5\n",
      "Example 4: 42\n",
      "Example 5: 624\n",
      "Example 6: 35\n",
      "Example 7: 48\n",
      "Example 8: 16\n",
      "Example 9: 41\n",
      "Example 10: 990\n",
      "Example 11: 121\n",
      "Example 12: 5\n",
      "Example 13: 85\n",
      "Example 14: 35\n",
      "Example 15: 5\n",
      "Example 16: 448000\n",
      "Example 17: 800\n",
      "Example 18: 43\n",
      "Example 19: 16\n",
      "Example 20: 16\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(few_shot_data):\n",
    "    pred = extract_final_answer(example[\"original_answer\"])\n",
    "    print(f\"Example {i+1}: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
